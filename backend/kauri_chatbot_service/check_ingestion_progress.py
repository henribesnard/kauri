#!/usr/bin/env python
"""
Script de suivi de la progression de l'ingestion
"""
import sys
import os
sys.path.insert(0, os.path.dirname(__file__))

from pathlib import Path
from src.rag.vector_store.chroma_store import get_chroma_store
from ingest_documents import load_existing_hashes

def main():
    print("\n" + "="*70)
    print("üìä PROGRESSION DE L'INGESTION")
    print("="*70)

    try:
        # Connexion √† ChromaDB
        chroma_store = get_chroma_store()

        # Compteurs
        total_chunks = chroma_store.count()

        # Charger les hashes pour compter les documents uniques
        hashes = load_existing_hashes(chroma_store)
        unique_docs = len(hashes)

        # Compter les fichiers totaux √† ing√©rer
        base_path = Path("/app/base_connaissances")
        docx_files = list(base_path.glob("**/*.docx"))
        pdf_files = list(base_path.glob("**/*.pdf"))
        total_files = len(docx_files) + len(pdf_files)

        # Calculs
        progress_pct = (unique_docs / total_files * 100) if total_files > 0 else 0
        remaining = total_files - unique_docs
        avg_chunks_per_doc = total_chunks / unique_docs if unique_docs > 0 else 0

        print(f"\nüìÅ Fichiers √† traiter:")
        print(f"   ‚Ä¢ Total:        {total_files} fichiers")
        print(f"   ‚Ä¢ DOCX:         {len(docx_files)}")
        print(f"   ‚Ä¢ PDF:          {len(pdf_files)}")

        print(f"\n‚úÖ Documents ing√©r√©s:")
        print(f"   ‚Ä¢ Uniques:      {unique_docs} documents")
        print(f"   ‚Ä¢ Restants:     {remaining} documents")
        print(f"   ‚Ä¢ Progression:  {progress_pct:.1f}%")

        print(f"\nüì¶ Chunks dans ChromaDB:")
        print(f"   ‚Ä¢ Total:        {total_chunks} chunks")
        print(f"   ‚Ä¢ Moyenne:      {avg_chunks_per_doc:.1f} chunks/doc")

        # Barre de progression
        bar_length = 50
        filled_length = int(bar_length * unique_docs // total_files)
        bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)

        print(f"\n[{bar}] {progress_pct:.1f}%")

        # Estimation du temps restant (bas√© sur ~5-8 secondes par document)
        if remaining > 0:
            avg_time_per_doc = 6  # secondes
            remaining_time_sec = remaining * avg_time_per_doc
            remaining_hours = remaining_time_sec / 3600
            remaining_minutes = (remaining_time_sec % 3600) / 60

            print(f"\n‚è±Ô∏è  Temps restant estim√©:")
            if remaining_hours >= 1:
                print(f"   ‚Ä¢ ~{remaining_hours:.1f} heures ({remaining_minutes:.0f} minutes)")
            else:
                print(f"   ‚Ä¢ ~{remaining_minutes:.0f} minutes")

        print("\n" + "="*70 + "\n")

        # Status de l'ingestion
        if unique_docs == 0:
            print("‚ö†Ô∏è  L'ingestion n'a pas encore d√©marr√©")
        elif unique_docs < total_files:
            print("üîÑ Ingestion en cours...")
            print("\nüí° Pour voir les logs en direct:")
            print("   docker exec kauri_chatbot_service tail -f /app/logs/ingestion.log")
        else:
            print("‚úÖ INGESTION TERMIN√âE!")
            print(f"\nüìä R√©sum√© final:")
            print(f"   ‚Ä¢ {unique_docs} documents ing√©r√©s")
            print(f"   ‚Ä¢ {total_chunks} chunks cr√©√©s")
            print(f"   ‚Ä¢ Moyenne: {avg_chunks_per_doc:.1f} chunks/document")

    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()

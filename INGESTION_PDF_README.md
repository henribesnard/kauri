# ğŸ“„ Support PDF et DÃ©duplication Intelligente - Documentation

## Vue d'ensemble des changements

Le systÃ¨me d'ingestion de KAURI a Ã©tÃ© amÃ©liorÃ© pour supporter les documents PDF en plus des DOCX, avec un systÃ¨me de dÃ©duplication intelligent basÃ© sur ChromaDB.

---

## âœ¨ Nouvelles fonctionnalitÃ©s

### 1. Support complet des PDFs

âœ… **Extraction de texte depuis PDFs** avec `pdfplumber`
âœ… **DÃ©tection et extraction de tableaux** dans les PDFs
âœ… **MÃ©tadonnÃ©es automatiques** (catÃ©gorie basÃ©e sur le chemin)
âœ… **Gestion des PDFs multi-pages**

### 2. DÃ©duplication intelligente

âœ… **Chargement des hashes depuis ChromaDB** au dÃ©marrage
âœ… **Skip automatique des documents dÃ©jÃ  ingÃ©rÃ©s**
âœ… **BasÃ© sur le hash SHA-256 du contenu**
âœ… **Persistance entre les exÃ©cutions**

### 3. ParamÃ¨tres de chunking optimisÃ©s

âœ… **Chunk size: 3500 caractÃ¨res** (taille universelle)
âœ… **Overlap: 300 caractÃ¨res** (sÃ©curise les transitions)

---

## ğŸ“ Structure des dossiers

```
base_connaissances/
â”œâ”€â”€ actes_uniformes/           (existant - DOCX)
â”œâ”€â”€ plan_comptable/             (existant - DOCX)
â”œâ”€â”€ presentation_ohada/         (existant - DOCX)
â”œâ”€â”€ doctrines/                  (nouveau - 974 PDFs dÃ©placÃ©s)
â””â”€â”€ jurisprudences/             (nouveau - 4034 PDFs dÃ©placÃ©s)
```

**Total: 5008 PDFs + documents DOCX existants**

---

## ğŸ”§ Modifications techniques

### Fichier: `src/ingestion/document_processor.py`

**AjoutÃ©:**
- `read_pdf()` - Extraction de texte depuis PDF avec pdfplumber
- `_table_to_text()` - Conversion des tableaux en format texte
- `_infer_category_from_path()` - DÃ©tection automatique de catÃ©gorie
- Support `.pdf` dans `SUPPORTED_FORMATS`
- Traitement PDF dans `process_file()`

**FonctionnalitÃ©s:**
```python
# Extraction de texte page par page
with pdfplumber.open(file_path) as pdf:
    for page in pdf.pages:
        text = page.extract_text()
        tables = page.extract_tables()
```

---

### Fichier: `ingest_documents.py`

**AjoutÃ©:**
- `load_existing_hashes()` - Charge les hashes depuis ChromaDB
- Support des PDFs dans `find_documents()`
- DÃ©duplication au dÃ©marrage de l'ingestion

**Logique de dÃ©duplication:**
```python
# Avant (âŒ)
processed_hashes = set()  # Vide Ã  chaque exÃ©cution

# AprÃ¨s (âœ…)
processed_hashes = load_existing_hashes(chroma_store)  # Charge depuis DB
```

**ParamÃ¨tres de chunking:**
```python
chunk_size = 3500      # CaractÃ¨res par chunk
chunk_overlap = 300    # Overlap entre chunks
```

---

## ğŸš€ Utilisation

### Lancer les tests

```bash
# Depuis le host
docker exec kauri_chatbot_service python test_pdf_ingestion.py
```

**Tests effectuÃ©s:**
1. âœ… Traitement d'un PDF
2. âœ… SystÃ¨me de dÃ©duplication
3. âœ… Recherche de fichiers

---

### Lancer l'ingestion complÃ¨te

```bash
# IngÃ©rer TOUS les documents (DOCX + PDF)
docker exec kauri_chatbot_service python ingest_documents.py
```

**Ce qui se passe:**
1. Connexion Ã  ChromaDB
2. Chargement des hashes existants (dÃ©duplication)
3. Recherche de tous les `.docx` et `.pdf` dans `base_connaissances/`
4. Pour chaque fichier:
   - Extraction du contenu
   - Calcul du hash SHA-256
   - **Skip si dÃ©jÃ  ingÃ©rÃ©** (hash existant)
   - Sinon: chunking â†’ embeddings â†’ ajout Ã  ChromaDB
5. Construction de l'index BM25
6. Affichage des statistiques

---

### RÃ©ingÃ©rer uniquement les nouveaux documents

```bash
# Ajouter de nouveaux PDFs dans base_connaissances/
cp nouveau_doc.pdf base_connaissances/doctrines/

# Relancer l'ingestion
docker exec kauri_chatbot_service python ingest_documents.py
```

**RÃ©sultat:**
- âœ… Documents existants: **skipped** (dÃ©duplication)
- âœ… Nouveaux documents: **ingÃ©rÃ©s**
- âœ… Pas de doublons dans ChromaDB

---

## ğŸ“Š Statistiques attendues

### PremiÃ¨re ingestion (base vide)

```
==============================================================
âœ… Ingestion terminÃ©e!
==============================================================
ğŸ“Š Statistiques:
  â€¢ Fichiers trouvÃ©s:      5008+
  â€¢ Documents crÃ©Ã©s:       5008+
  â€¢ Documents ignorÃ©s:     0 (dÃ©jÃ  existants)
  â€¢ Ã‰checs:                0-10 (fichiers corrompus Ã©ventuels)
  â€¢ Taux de succÃ¨s:        99.8%
==============================================================

ğŸ“¦ ChromaDB: ~50000+ chunks indexÃ©s
```

### RÃ©ingestion (avec documents existants)

```
==============================================================
âœ… Ingestion terminÃ©e!
==============================================================
ğŸ“Š Statistiques:
  â€¢ Fichiers trouvÃ©s:      5008+
  â€¢ Documents crÃ©Ã©s:       5
  â€¢ Documents ignorÃ©s:     5003+ (dÃ©jÃ  existants)
  â€¢ Ã‰checs:                0
  â€¢ Taux de succÃ¨s:        100%
==============================================================

ğŸ“¦ ChromaDB: ~50050+ chunks indexÃ©s
```

---

## ğŸ” VÃ©rification de la persistance

### VÃ©rifier que ChromaDB persiste les donnÃ©es

```bash
# RedÃ©marrer les services
docker-compose restart

# VÃ©rifier le nombre de documents
docker exec kauri_chatbot_service python -c "
from src.rag.vector_store.chroma_store import get_chroma_store
store = get_chroma_store()
print(f'Documents in ChromaDB: {store.count()}')
"
```

**Si le nombre reste identique:** âœ… Persistance active
**Si le nombre = 0:** âŒ ProblÃ¨me de volume Docker

---

## âš™ï¸ Configuration ChromaDB

Le `docker-compose.yml` est configurÃ© pour la persistance:

```yaml
chromadb:
  environment:
    IS_PERSISTENT: "True"     # âœ… Persistance activÃ©e
  volumes:
    - chromadb_data:/chroma/chroma  # âœ… Volume Docker
```

**Volume nommÃ©:**
```yaml
volumes:
  chromadb_data:
    name: kauri_chromadb_data
```

---

## ğŸ› Troubleshooting

### Erreur: "Unsupported format: .pdf"

**Cause:** Ancienne version du code
**Solution:**
```bash
docker-compose down
docker-compose build kauri_chatbot_service
docker-compose up -d
```

### Tous les documents sont "skipped"

**Cause:** Documents dÃ©jÃ  ingÃ©rÃ©s
**C'est normal !** Le systÃ¨me de dÃ©duplication fonctionne.

**Pour forcer la rÃ©ingestion:**
```bash
# ATTENTION: Efface TOUTE la base ChromaDB
docker exec kauri_chatbot_service python -c "
from src.rag.vector_store.chroma_store import get_chroma_store
store = get_chroma_store()
store.clear()
print('ChromaDB cleared')
"

# Puis rÃ©ingÃ©rer
docker exec kauri_chatbot_service python ingest_documents.py
```

### PDFs ne sont pas trouvÃ©s

**VÃ©rifier:**
```bash
# Depuis le host
ls -la base_connaissances/doctrines/ | head
ls -la base_connaissances/jurisprudences/ | head

# Depuis le conteneur
docker exec kauri_chatbot_service ls -la /app/base_connaissances/doctrines/ | head
```

**Volume mapping dans docker-compose.yml:**
```yaml
volumes:
  - ./base_connaissances:/app/base_connaissances:ro
```

---

## ğŸ“ˆ Performance

### Temps d'ingestion estimÃ©s

| Documents | Chunks | Temps estimÃ© |
|-----------|--------|--------------|
| 100 PDFs | ~1000 | 2-5 minutes |
| 1000 PDFs | ~10000 | 20-50 minutes |
| 5008 PDFs | ~50000 | 1.5-3 heures |

**Facteurs d'impact:**
- Taille des PDFs
- CPU disponible
- Vitesse rÃ©seau (embeddings API)
- Nombre de tableaux

---

## ğŸ¯ Prochaines Ã©tapes

### Optimisations possibles

1. **Batch processing** - Traiter les documents par lots
2. **Parallel ingestion** - Utiliser asyncio pour parallÃ©liser
3. **Embedding cache** - Cacher les embeddings calculÃ©s
4. **Index incremental** - Mettre Ã  jour BM25 de faÃ§on incrÃ©mentale
5. **Monitoring** - Ajouter des mÃ©triques Prometheus

### AmÃ©liorations fonctionnelles

1. **OCR pour PDFs scannÃ©s** - IntÃ©grer le service kauri_ocr_service
2. **Extraction d'entitÃ©s** - DÃ©tecter dates, montants, articles
3. **Classification automatique** - ML pour catÃ©goriser les documents
4. **RÃ©sumÃ©s automatiques** - GÃ©nÃ©rer des rÃ©sumÃ©s avec LLM
5. **Interface web** - Dashboard pour suivre l'ingestion

---

## ğŸ“š Ressources

- **pdfplumber docs**: https://github.com/jsvine/pdfplumber
- **ChromaDB docs**: https://docs.trychroma.com/
- **KAURI architecture**: `backend/ARCHITECTURE_DECISION.md`

---

## âœ… Checklist de validation

- [x] Support PDF ajoutÃ© dans document_processor
- [x] DÃ©duplication depuis ChromaDB implÃ©mentÃ©e
- [x] find_documents() trouve les PDFs
- [x] Chunk size / overlap configurÃ©s (3500/300)
- [x] 974 doctrines dÃ©placÃ©es vers base_connaissances/
- [x] 4034 jurisprudences dÃ©placÃ©es vers base_connaissances/
- [x] Script de test crÃ©Ã©
- [x] Documentation complÃ¨te
- [ ] Tests exÃ©cutÃ©s avec succÃ¨s
- [ ] Ingestion complÃ¨te lancÃ©e
- [ ] VÃ©rification de la persistance

---

**DÃ©veloppÃ© pour KAURI - Expertise comptable OHADA** ğŸ‡«ğŸ‡·ğŸ‡¨ğŸ‡®
